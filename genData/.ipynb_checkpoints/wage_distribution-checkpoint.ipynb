{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9a8549c8-6010-45f6-a676-9440fde067fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0fc51b40-2dec-4df3-be89-e4a7ec9024d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################# GLOBAL VARIABLES ######################\n",
    "\n",
    "# Definitions from PLFS 2018-19 Annual Report, Concepts and Definitions (2.38.1)\n",
    "# Problematic codes for self employed criteria: `21` - worked in household enterprises (self-employed) as helper\n",
    "SELF_EMP_CODES = [\"11\", \"12\", \"21\"]\n",
    "REG_EMP_CODES = [\"31\"]\n",
    "CASUAL_EMP_CODES = [\"41\", \"42\", \"51\", \"61\", \"62\", \"71\", \"72\"]\n",
    "\n",
    "NOT_REG_CODES = SELF_EMP_CODES + CASUAL_EMP_CODES\n",
    "\n",
    "EMP_CODES = SELF_EMP_CODES + REG_EMP_CODES + CASUAL_EMP_CODES\n",
    "UNEMP_CODES = [\"81\", \"82\"]\n",
    "LF_CODES = EMP_CODES + UNEMP_CODES\n",
    "NOT_IN_LF_CODES = [str(x) for x in list(range(91,100))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "330f5900-d3d4-41c7-9578-d27e6c4cda00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Main Data File\n",
    "df_per_fv = pd.read_stata(\"../../data/raw/plfs/plfs_2018_19/PerV1_2018-19.dta\")\n",
    "df_per_rv = pd.read_stata(\"../../data/raw/plfs/plfs_2018_19/PerRV_2018-19.dta\") \n",
    "df_hh_fv = pd.read_stata('../../data/raw/plfs/plfs_2018_19/HHV1_2018-19.dta')\n",
    "df_hh_rv = pd.read_stata('../../data/raw/plfs/plfs_2018_19/HHRV_2018-19.dta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aed5ef85-0924-4148-9c7e-824d26f0ca9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533264, 104)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_per_rv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf8c15c-d797-4bde-b3b0-f5a3e53c9fec",
   "metadata": {},
   "source": [
    "### On whether to use Repeat Visit along with the First Visit Data (even if to use it as a pooled cross-section) \n",
    "\n",
    "There are two ways in which employment status is determined: 1) What you did in the last 365 days. 2) What you did in the last week. Repeat visit does not have information about the first one. Only the Weekly status. Using either has its pros and cons. While the first may be more accurate picture of participation while the second has more data. I am sticking with First Visit only (for simplicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1b93cfae-d79d-45e3-96ac-c69118f4238a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This block makes a csv file which stores the variable name-label pairs. \n",
    "df_per_fv_layout = pd.read_excel(\"../../data/raw/plfs/plfs_2018_19/Data_LayoutPLFS.xlsx\", header=38, usecols=[1], nrows=129)\n",
    "df_hh_fv_layout = pd.read_excel(\"../../data/raw/plfs/plfs_2018_19/Data_LayoutPLFS.xlsx\", header=2, usecols=[1], nrows=32)\n",
    "# df_hh_rv_layout = copy.deepcopy(df_hh_fv_layout) \n",
    "# df_per_rv_layout = pd.read_excel(\"../../data/raw/plfs/plfs_2018_19/Data_LayoutPLFS.xlsx\", header=171, usecols=[1], nrows=104)\n",
    "\n",
    "pd.DataFrame({'varName': df_per_fv.columns, 'varLabel': df_per_fv_layout[\"Full Name\"]}).to_csv(\"../../data/proc/ColNameLabelPerV1_2018_19.csv\", index=False)\n",
    "pd.DataFrame({'varName': df_hh_fv.columns, 'varLabel': df_hh_fv_layout[\"Full Name\"]}).to_csv(\"../../data/proc/ColNameLabelHHV1_2018_19.csv\", index=False)\n",
    "# pd.DataFrame({'varName': df_hh_rv.columns, 'varLabel': df_hh_rv_layout[\"Full Name\"]}).to_csv(\"../../data/proc/ColNameLabelHHRV_2018_19.csv\", index=False)\n",
    "# pd.DataFrame({'varName': df_per_rv.columns, 'varLabel': df_per_rv_layout[\"Full Name\"]}).to_csv(\"../../data/proc/ColNameLabelPerRV_2018_19.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f0c654d6-140e-485b-83d4-4f7368f8e08b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_10012\\3645976382.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_per_fv.loc[:,'HHID'] = df_per_fv.quarter_per_fv + df_per_fv.visit_per_fv + df_per_fv.fsu_per_fv \\\n"
     ]
    }
   ],
   "source": [
    "# Merge HH and Per dataset\n",
    "# generate merge keys for both hh and per datasets and merge\n",
    "df_per_fv.loc[:,'HHID'] = df_per_fv.quarter_per_fv + df_per_fv.visit_per_fv + df_per_fv.fsu_per_fv \\\n",
    "                    + df_per_fv.b1q13_per_fv + df_per_fv.b1q14_per_fv + df_per_fv.b1q15_per_fv\n",
    "\n",
    "df_hh_fv.loc[:,'HHID'] = df_hh_fv.qtr_hh_rv + df_hh_fv.visit_hh_rv + df_hh_fv.b1q1_hh_rv \\\n",
    "                    + df_hh_fv.b1q13_hh_rv + df_hh_fv.b1q14_hh_rv + df_hh_fv.b1q15_hh_rv \n",
    "\n",
    "\n",
    "df_temp = pd.merge(left=df_per_fv, right=df_hh_fv, on='HHID', how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fbe7ec6f-66ab-44c9-93ee-a2e2810660a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just so that I don't have to merge again and again\n",
    "df_merged = copy.deepcopy(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7a432522-c154-4875-bf8c-360648322bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420757, 162)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ea1d0237-e590-40d5-8bf2-f35e9bd787eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subsetting: \n",
    "# 1. (Currently) married people. \n",
    "df_merged = df_merged[df_merged[\"b4q7_per_fv\"] == \"2\"]\n",
    "# 2. Urban.\n",
    "df_merged = df_merged[df_merged[\"b1q3_per_fv\"] == \"2\"]\n",
    "# 3. Drop 3rd gender\n",
    "df_merged = df_merged[df_merged[\"b4q5_per_fv\"] != \"3\"]\n",
    "# 4. Then make a dataframe with husbands and wives matched. Then subset women with age 15-49. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "77d758db-2384-444d-89a6-8938609daf3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89513, 162)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd573437-a1ba-4d87-aa1e-fde00560c7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######### Employment Status \n",
    "## This is calculated using UPSS (Usual Principal or Subsidiary Status) definition. See Afridi et al. (2022) Appendix B\n",
    "\n",
    "df_merged.loc[:,\"lfp_ps\"] = df_merged.b5pt1q3_per_fv.apply(lambda x: 1 if x in LF_CODES else 0)\n",
    "df_merged[\"lfp_ss\"] = df_merged.b5pt2q3_per_fv.apply(lambda x: 1 if x in LF_CODES else 0)\n",
    "df_merged[\"lfp_ps_ss\"] = df_merged['lfp_ps'] + df_merged['lfp_ss']\n",
    "\n",
    "df_merged.loc[:,\"emp_ps\"] = df_merged.b5pt1q3_per_fv.apply(lambda x: 1 if x in EMP_CODES else 0)\n",
    "df_merged[\"emp_ss\"] = df_merged.b5pt2q3_per_fv.apply(lambda x: 1 if x in EMP_CODES else 0)\n",
    "df_merged[\"emp_ps_ss\"] = df_merged['emp_ps'] + df_merged['emp_ss']\n",
    "/\n",
    "df_merged.loc[:,'EMP'] = 0\n",
    "df_merged.loc[df_merged['emp_ps'] > 0, 'EMP'] = 1\n",
    "\n",
    "df_merged.loc[:,\"LFP\"] = 0\n",
    "df_merged.loc[df_merged[\"lfp_ps_ss\"] > 0,\"LFP\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "84a02bd1-ba33-46ce-9916-d13416c74e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44824, 170)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged[\"EMP\"] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4d0147c6-1500-4c28-9e28-91050e6d452d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b6q5_per_fv\n",
       "11.0    14941\n",
       "12.0     1734\n",
       "21.0     1905\n",
       "31.0    19960\n",
       "41.0       27\n",
       "42.0       32\n",
       "51.0     4875\n",
       "61.0       89\n",
       "62.0      436\n",
       "71.0       59\n",
       "72.0      315\n",
       "81.0     1593\n",
       "82.0      351\n",
       "91.0      409\n",
       "92.0    32114\n",
       "93.0     3894\n",
       "94.0     5052\n",
       "95.0      611\n",
       "97.0     1018\n",
       "98.0       98\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['b6q5_per_fv'].astype(float).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1b7bbf29-2e02-4dd5-8754-4b8ca90502f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### Get hourly wages.\n",
    "# These will exist only for those that are employed so I will subset.\n",
    "# DONT SUBSET ANY MORE THAN YOU HAVE TO!!!!!!\n",
    "# df_merged = df_merged[df_merged['EMP'] == 1]\n",
    "df_merged.loc[:,'hourlywage'] = pd.Series(None)\n",
    "# Wage column names\n",
    "wage_cols = ['b6q9_per_fv', 'b6q10_per_fv', \\\n",
    "             'b6q9_3pt1_Act1_per_fv', 'b6q9_3pt1_Act2_per_fv', 'b6q9_3pt2_Act1_per_fv', \\\n",
    "             'b6q9_3pt2_Act2_per_fv', 'b6q9_3pt3_Act1_per_fv', 'b6q9_3pt3_Act2_per_fv', \\\n",
    "             'b6q9_3pt4_Act1_per_fv', 'b6q9_3pt4_Act2_per_fv', 'b6q9_3pt5_Act1_per_fv', \\\n",
    "             'b6q9_3pt5_Act2', 'b6q9_Act2_3pt6', 'b6q9_3pt6_Act1', 'b6q9_Act1_3pt7', \\\n",
    "             'b6q9_Act2_3pt7']\n",
    "# these objects are strings so need to be converted to float.\n",
    "for col in wage_cols:\n",
    "    df_merged.loc[:,col] = df_merged.loc[:,col].astype(float)\n",
    "\n",
    "\n",
    "# Some codes have salaries given for last 30 days.\n",
    "# so extracting them here:\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['31', '71', '72']),'wage'] = df_merged.loc[df_merged['b6q5_per_fv'].isin(['31', '71', '72']),'b6q9_per_fv']\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62']),'wage'] = df_merged.loc[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62']),'b6q10_per_fv']\n",
    "\n",
    "# Next, get wages for other codes (from their weekly activities)\n",
    "# that have wages by day.\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['41', '42', '51']),'wage'] = \\\n",
    "                                        df_merged[df_merged['b6q5_per_fv'].isin(['41', '42', '51'])]\\\n",
    "                                               [['b6q9_3pt1_Act1_per_fv', 'b6q9_3pt1_Act2_per_fv', 'b6q9_3pt2_Act1_per_fv', \\\n",
    "                                                 'b6q9_3pt2_Act2_per_fv', 'b6q9_3pt3_Act1_per_fv', 'b6q9_3pt3_Act2_per_fv', \\\n",
    "                                                 'b6q9_3pt4_Act1_per_fv', 'b6q9_3pt4_Act2_per_fv', 'b6q9_3pt5_Act1_per_fv', \\\n",
    "                                                 'b6q9_3pt5_Act2', 'b6q9_Act2_3pt6', 'b6q9_3pt6_Act1', 'b6q9_Act1_3pt7', \\\n",
    "                                                 'b6q9_Act2_3pt7']].sum(axis=1)\n",
    "\n",
    "\n",
    "# Changing `wage` type from object to float.\n",
    "df_merged.loc[:,'wage'] = df_merged.loc[:,'wage'].astype(float)\n",
    "\n",
    "# wageFreq is \"monthly\" or \"weekly\"\n",
    "df_merged.loc[:,'wageFreq'] = pd.Series(None)\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62', '31', '71', '72']),'wageFreq'] = \"m\"\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['41', '42', '51']),'wageFreq'] = \"w\"\n",
    "\n",
    "## End Getting Wages\n",
    "\n",
    "## Get Hours Worked.\n",
    "time_cols = ['b6q6_3pt1_Act1_per_fv', 'b6q6_3pt1_Act2_per_fv', 'b6q6_3pt2_Act1_per_fv', \\\n",
    "             'b6q6_3pt2_Act2_per_fv', 'b6q6_3pt3_Act1_per_fv', 'b6q6_3pt3_Act2_per_fv', \\\n",
    "             'b6q6_3pt4_Act1_per_fv', 'b6q6_3pt4_Act2_per_fv', 'b6q6_3pt5_Act1_per_fv', \\\n",
    "             'b6q6_3pt5_Act2', 'b6q6_3pt6_Act1', 'b6q6_3pt6_Act2', 'b6q6_3pt7_Act1', \\\n",
    "             'b6q6_3pt7_Act2']\n",
    "for col in time_cols:\n",
    "    df_merged.loc[:,col] = df_merged.loc[:,col].astype(float)\n",
    "df_merged.loc[:,'weeklyhrs'] = df_merged.loc[:,time_cols].sum(axis=1)\n",
    "## End Hours Worked\n",
    "\n",
    "df_merged = df_merged[(df_merged['weeklyhrs'] > 0)]\n",
    "df_merged = df_merged[df_merged['wage'] > 0]\n",
    "# 144 hrs time endowment. Drop any with more than that.\n",
    "# df_merged = df_merged[df_merged['weeklyhrs'] <= 144]\n",
    "# Can remove lower end?  Those working very very few hrs.\n",
    "# df_merged = df_merged[df_merged['weeklyhrs'] > df_merged['weeklyhrs'].quantile(0.001)]\n",
    "df_merged[\"factor\"] = df_merged[\"weeklyhrs\"]\n",
    "df_merged.loc[df_merged[\"wageFreq\"] == \"m\", \"factor\"] = 4*df_merged.loc[df_merged[\"wageFreq\"] == \"m\",\"weeklyhrs\"]\n",
    "df_merged['hourlywage'] = df_merged['wage']/df_merged['factor']\n",
    "\n",
    "\n",
    "df_merged.loc[:,'FT'] = pd.Series(None)\n",
    "df_merged.loc[df_merged['weeklyhrs'] >= 40,'FT'] = \"FT\"\n",
    "df_merged.loc[df_merged['weeklyhrs'] < 40 ,'FT'] = \"PT\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b9b87f4c-754e-4c3a-9159-e352a66e5d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Let's try getting daily wage\n",
    "df_merged.loc[:,'dailywage'] = pd.Series(None)\n",
    "df_merged.loc[df_merged[\"wageFreq\"] == \"m\",\"dailywage\"] = df_merged.loc[df_merged[\"wageFreq\"] == \"m\",\"wage\"]/30\n",
    "df_merged.loc[df_merged[\"wageFreq\"] == \"w\",\"dailywage\"] = df_merged.loc[df_merged[\"wageFreq\"] == \"w\",\"wage\"]/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "85061fab-98eb-4236-b55f-d7f23aa4afbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19698.000000\n",
       "mean       694.139779\n",
       "std        602.690928\n",
       "min          4.100000\n",
       "25%        283.333333\n",
       "50%        500.000000\n",
       "75%       1000.000000\n",
       "max      10666.666667\n",
       "Name: dailywage, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['b6q5_per_fv'].isin(['31', '71', '72'])][\"dailywage\"].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3187cd0a-a1df-49a2-bde3-09d00a81663a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     21337.000000\n",
       "mean        477.599550\n",
       "std        1428.411814\n",
       "min           3.333333\n",
       "25%         250.000000\n",
       "50%         350.000000\n",
       "75%         566.666667\n",
       "max      200000.000000\n",
       "Name: dailywage, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62','41', '42', '51'])][\"dailywage\"].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0e6001ee-d619-4276-933d-4327b9d6d0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = df_merged[df_merged[\"weeklyhrs\"] < df_merged[\"weeklyhrs\"].astype(float).quantile(0.9996)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "709ad254-f469-4ff0-b263-b914dd18638a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19698.000000\n",
       "mean        57.650878\n",
       "std          9.967689\n",
       "min          7.000000\n",
       "25%         56.000000\n",
       "50%         56.000000\n",
       "75%         62.000000\n",
       "max        107.000000\n",
       "Name: weeklyhrs, dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"weeklyhrs\"].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f31838e4-b67a-4e10-b53a-4b46ab25f122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    41903.000000\n",
       "mean        78.765028\n",
       "std        157.227044\n",
       "min          0.446429\n",
       "25%         35.714286\n",
       "50%         53.571429\n",
       "75%         94.339623\n",
       "max      26785.714286\n",
       "Name: hourlywage, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['hourlywage'].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "71c79004-345e-4d53-83f1-0b6b7baa99fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just so that I don't have to merge again and again\n",
    "df_merged = copy.deepcopy(df_temp)\n",
    "\n",
    "# Subsetting: \n",
    "# 1. (Currently) married people. \n",
    "df_merged = df_merged[df_merged[\"b4q7_per_fv\"] == \"2\"]\n",
    "# 2. Urban.\n",
    "df_merged = df_merged[df_merged[\"b1q3_per_fv\"] == \"2\"]\n",
    "# 3. Drop 3rd gender\n",
    "df_merged = df_merged[df_merged[\"b4q5_per_fv\"] != \"3\"]\n",
    "# 4. Then make a dataframe with husbands and wives matched. Then subset women with age 15-49. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2f8c0734-3d96-431b-b3d0-9c128fb1dcb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######### Employment Status \n",
    "## This is calculated using UPSS (Usual Principal or Subsidiary Status) definition. See Afridi et al. (2022) Appendix B\n",
    "\n",
    "df_merged.loc[:,\"lfp_ps\"] = df_merged.b5pt1q3_per_fv.apply(lambda x: 1 if x in LF_CODES else 0)\n",
    "df_merged[\"lfp_ss\"] = df_merged.b5pt2q3_per_fv.apply(lambda x: 1 if x in LF_CODES else 0)\n",
    "df_merged[\"lfp_ps_ss\"] = df_merged['lfp_ps'] + df_merged['lfp_ss']\n",
    "\n",
    "df_merged.loc[:,\"emp_ps\"] = df_merged.b5pt1q3_per_fv.apply(lambda x: 1 if x in EMP_CODES else 0)\n",
    "df_merged[\"emp_ss\"] = df_merged.b5pt2q3_per_fv.apply(lambda x: 1 if x in EMP_CODES else 0)\n",
    "df_merged[\"emp_ps_ss\"] = df_merged['emp_ps'] + df_merged['emp_ss']\n",
    "\n",
    "df_merged.loc[:,'EMP'] = 0\n",
    "df_merged.loc[df_merged['emp_ps'] > 0, 'EMP'] = 1\n",
    "\n",
    "df_merged.loc[:,\"LFP\"] = 0\n",
    "df_merged.loc[df_merged[\"lfp_ps_ss\"] > 0,\"LFP\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3e5b891b-3276-4b1f-a0dc-a062ab0d75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this block, I create a dataframe with husbands and wives. \n",
    "# First, remove all entries that do not have relation to head of HH as: 1,2,3 or 4. These relations are the only ones where I can identify a marriage. \n",
    "df_merged = df_merged[df_merged[\"b4q4_per_fv\"].isin([\"1\",\"2\",\"3\",\"4\"])]\n",
    "\n",
    "# Next, need to label each person in a HH as husband/wife. \n",
    "df_merged.loc[:,\"spouse\"] = \"husband\"\n",
    "df_merged.loc[df_merged[\"b4q5_per_fv\"] == \"2\",\"spouse\"] = \"wife\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "96b2d457-c890-4738-877e-03490bc491a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b4q4_per_fv  spouse \n",
       "1            husband    34593\n",
       "2            wife       33692\n",
       "4            wife        8192\n",
       "3            husband     7859\n",
       "1            wife        1140\n",
       "3            wife         838\n",
       "4            husband      314\n",
       "2            husband      174\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[[\"b4q4_per_fv\", \"spouse\"]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61979294-b30e-4098-9a6e-5b50769d4bc1",
   "metadata": {},
   "source": [
    "Why are husbands and wives not equal? \n",
    "I was subsetting by EMployment status. Many  more husbands were employed but not so many wives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4efaa9ef-0bdc-438d-9047-a0d98e3d5bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_10012\\1110488405.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_husb.loc[:,\"rel_key\"] = pd.Series(None)\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_10012\\1110488405.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wife.loc[:,\"rel_key\"] = pd.Series(None)\n"
     ]
    }
   ],
   "source": [
    "# Make two separate dataframes for husbands and wives, merge each husband with his wife.\n",
    "# \n",
    "# In each HH, there is a possibility that you have two husbands and two wives. \n",
    "# Separate the husbands and wives. \n",
    "df_husb = df_merged[df_merged[\"spouse\"] == \"husband\"]\n",
    "df_wife = df_merged[df_merged[\"spouse\"] == \"wife\"]\n",
    "\n",
    "# # Now, define a mapping -- 1<->2, 3<->4 within each hh has to be mapped.\n",
    "# # The relationship key will be kept the same as b4q4_per_fv for husbands. Relationship key \n",
    "# # for wives will be according to the merge map. \n",
    "df_husb.loc[:,\"rel_key\"] = pd.Series(None)\n",
    "df_wife.loc[:,\"rel_key\"] = pd.Series(None)\n",
    "df_husb.loc[:,\"rel_key\"] = df_husb.loc[:,\"b4q4_per_fv\"]\n",
    "merge_map = {\"1\":\"2\", \"2\":\"1\", \"3\":\"4\", \"4\":\"3\"}\n",
    "df_wife.loc[:,\"rel_key\"] = df_wife.loc[:,\"b4q4_per_fv\"].apply(lambda x: merge_map[x])\n",
    "# # df_husb[\"rel_key\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9b0d8bf2-d3ac-4265-8b8e-723b4099ad2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42940, 172)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_husb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "46aaeefd-01de-4643-b876-5989f39ebeee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43862, 172)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wife.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "287a7fba-b831-4ee1-a2bb-39ad9549afbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update column names so that husb. cols have _husb, wives, _wife\n",
    "df_husb.columns = [col+\"_h\" for col in df_husb.columns]\n",
    "df_wife.columns = [col+\"_w\" for col in df_wife.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "39ab141c-e8d0-48fd-a2fd-a53b14dbbd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_husb_wife = pd.merge(left=df_husb, right=df_wife, left_on=[\"HHID_h\", \"rel_key_h\"], right_on=[\"HHID_w\", \"rel_key_w\"], how=\"outer\", indicator=True)\n",
    "# df_husb_wife = df_husb_wife[df_husb_wife[\"_merge\"] == \"both\"]\n",
    "# df_husb_wife.drop(columns=[\"_merge\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "13a1c6fb-273b-4b59-970c-db0c8bbf9307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          43825\n",
       "right_only     2329\n",
       "left_only      1524\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_husb_wife[\"_merge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c504e620-ca94-4f23-a7a0-c1972cfca42f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_husb_wife = df_husb_wife[df_husb_wife[\"_merge\"] == \"both\"]\n",
    "# Now subset based on wife's age: I need women with age in 15-49\n",
    "df_husb_wife = df_husb_wife[(df_husb_wife[\"b4q6_per_fv_w\"] >= 15) & (df_husb_wife[\"b4q6_per_fv_w\"] <= 49)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9cc447a4-778e-433b-b5b5-a30bd0cede0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the table for LFP status\n",
    "df_husb_wife.loc[:,\"EMP_type\"] = pd.Series(None)\n",
    "df_husb_wife.loc[(df_husb_wife[\"EMP_h\"] == 1) & (df_husb_wife[\"EMP_w\"] == 1),\"EMP_type\"] = \"YY\"\n",
    "df_husb_wife.loc[(df_husb_wife[\"EMP_h\"] == 1) & (df_husb_wife[\"EMP_w\"] == 0),\"EMP_type\"] = \"YN\"\n",
    "df_husb_wife.loc[(df_husb_wife[\"EMP_h\"] == 0) & (df_husb_wife[\"EMP_w\"] == 1),\"EMP_type\"] = \"NY\"\n",
    "df_husb_wife.loc[(df_husb_wife[\"EMP_h\"] == 0) & (df_husb_wife[\"EMP_w\"] == 0),\"EMP_type\"] = \"NN\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2bcfb94d-ef4c-4dd1-95db-284d2647598b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMP_type\n",
       "YN    0.785408\n",
       "YY    0.164659\n",
       "NN    0.039396\n",
       "NY    0.010537\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_husb_wife[\"EMP_type\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3493a6d8-6768-4cc9-9cc1-0e7a243d9a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove entries that don't satisfy the mapping as above\n",
    "qtr_month_map = {\"Q5\": [\"7\",\"8\",\"9\"], \"Q6\": [\"10\",\"11\",\"12\"], \"Q7\": [\"1\", \"2\", \"3\"], \"Q8\": [\"4\", \"5\", \"6\"]}\n",
    "correct_qtr_month = []\n",
    "for qtr, months in qtr_month_map.items():\n",
    "    for month in months:\n",
    "        correct_qtr_month.append(qtr+month)\n",
    "\n",
    "df_merged['qtr_month'] = df_merged['qtr_hh_rv'] + df_merged['b1q9_hh_rv']\n",
    "df_merged['correct_qtr_month'] = df_merged['qtr_month'].apply(lambda x: 1 if x in correct_qtr_month else 0)\n",
    "df_merged = df_merged[df_merged['correct_qtr_month'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e43c9da-7d00-41b1-b3fd-954dc10f6456",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qtr_hh_rv  b1q9_hh_rv\n",
       "Q5         7             40749\n",
       "           8             35746\n",
       "           9             29892\n",
       "Q6         10            37904\n",
       "           11            36243\n",
       "           12            30697\n",
       "Q7         1             39117\n",
       "           2             35621\n",
       "           3             30166\n",
       "Q8         4             29047\n",
       "           5             39392\n",
       "           6             34415\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[['qtr_hh_rv','b1q9_hh_rv']].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfb618e-e7d4-48d6-90e7-a20c0b72aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Weights \n",
    "df_merged['weight'] = df_merged['MULT_per_fv']/2\n",
    "df_merged.loc[df_merged['NSS_per_fv'] == df_merged['NSC_per_fv'], 'weight'] = df_merged.loc[df_merged['NSS_per_fv'] == df_merged['NSC_per_fv'],'MULT_per_fv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a14e1072-d0a5-474a-993f-f8a47d8e8a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop 3rd gender\n",
    "df_merged = df_merged[df_merged['b4q5_per_fv'] != '3']\n",
    "# df_copy = df_merged[(df_merged['b4q6_per_fv'] <= 45) & (df_merged['b4q6_per_fv'] >= 20) & (df_merged.b1q3_per_fv == '2')]\n",
    "\n",
    "# I only need these for married people living between the age of 15-65\n",
    "df_merged = df_merged[(df_merged['b4q6_per_fv'] <= 65) & (df_merged['b4q6_per_fv'] >= 15) & (df_merged[\"b4q7_per_fv\"] == \"2\")]\n",
    "# df_merged.groupby(['b4q5_per_fv']).apply(lambda x: np.average(x.EMP, weights=x.weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb3d6d8-719c-4632-b090-806c4041df87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_copy\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb4q5_per_fv\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39maverage(x\u001b[38;5;241m.\u001b[39mLFP, weights\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mweight))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_copy' is not defined"
     ]
    }
   ],
   "source": [
    "# df_copy.groupby(['b4q5_per_fv']).apply(lambda x: np.average(x.LFP, weights=x.weight))\n",
    "# df_merged[['b4q5_per_fv', 'LFP']].groupby(['b4q5_per_fv']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdddc2a4-eb91-428e-a0b2-db04ef0ad416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged[['b6q9_per_fv', 'b6q10_per_fv', \\\n",
    "             'b6q9_3pt1_Act1_per_fv', 'b6q9_3pt1_Act2_per_fv', 'b6q9_3pt2_Act1_per_fv', \\\n",
    "             'b6q9_3pt2_Act2_per_fv', 'b6q9_3pt3_Act1_per_fv', 'b6q9_3pt3_Act2_per_fv', \\\n",
    "             'b6q9_3pt4_Act1_per_fv', 'b6q9_3pt4_Act2_per_fv', 'b6q9_3pt5_Act1_per_fv', \\\n",
    "             'b6q9_3pt5_Act2', 'b6q9_Act2_3pt6', 'b6q9_3pt6_Act1', 'b6q9_Act1_3pt7', \\\n",
    "             'b6q9_Act2_3pt7']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca62c93-1730-4651-ba87-9ec8aed8ebba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get Hourly Wages\n",
    "# These will exist only for those that are employed so I will subset.\n",
    "df_merged = df_merged[df_merged['EMP'] == 1]\n",
    "df_merged.loc[:,'hourlywage'] = pd.Series(None)\n",
    "\n",
    "## First Getting Wages.\n",
    "df_merged.loc[:,'wage'] = pd.Series(None)\n",
    "# Wage column names\n",
    "wage_cols = ['b6q9_per_fv', 'b6q10_per_fv', \\\n",
    "             'b6q9_3pt1_Act1_per_fv', 'b6q9_3pt1_Act2_per_fv', 'b6q9_3pt2_Act1_per_fv', \\\n",
    "             'b6q9_3pt2_Act2_per_fv', 'b6q9_3pt3_Act1_per_fv', 'b6q9_3pt3_Act2_per_fv', \\\n",
    "             'b6q9_3pt4_Act1_per_fv', 'b6q9_3pt4_Act2_per_fv', 'b6q9_3pt5_Act1_per_fv', \\\n",
    "             'b6q9_3pt5_Act2', 'b6q9_Act2_3pt6', 'b6q9_3pt6_Act1', 'b6q9_Act1_3pt7', \\\n",
    "             'b6q9_Act2_3pt7']\n",
    "# these objects are strings so need to be converted to float.\n",
    "for col in wage_cols:\n",
    "    df_merged.loc[:,col] = df_merged.loc[:,col].astype(float)\n",
    "\n",
    "# Some codes have salaries given for last 30 days.\n",
    "# so extracting them here:\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['31', '71', '72']),'wage'] = df_merged.loc[df_merged['b6q5_per_fv'].isin(['31', '71', '72']),'b6q9_per_fv']\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62']),'wage'] = df_merged.loc[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62']),'b6q10_per_fv']\n",
    "\n",
    "# Next, get wages for other codes (from their weekly activities)\n",
    "# that have wages by day.\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['41', '42', '51']),'wage'] = \\\n",
    "                                        df_merged[df_merged['b6q5_per_fv'].isin(['41', '42', '51'])]\\\n",
    "                                               [['b6q9_3pt1_Act1_per_fv', 'b6q9_3pt1_Act2_per_fv', 'b6q9_3pt2_Act1_per_fv', \\\n",
    "                                                 'b6q9_3pt2_Act2_per_fv', 'b6q9_3pt3_Act1_per_fv', 'b6q9_3pt3_Act2_per_fv', \\\n",
    "                                                 'b6q9_3pt4_Act1_per_fv', 'b6q9_3pt4_Act2_per_fv', 'b6q9_3pt5_Act1_per_fv', \\\n",
    "                                                 'b6q9_3pt5_Act2', 'b6q9_Act2_3pt6', 'b6q9_3pt6_Act1', 'b6q9_Act1_3pt7', \\\n",
    "                                                 'b6q9_Act2_3pt7']].sum(axis=1)\n",
    "\n",
    "# Changing `wage` type from object to float.\n",
    "df_merged.loc[:,'wage'] = df_merged.loc[:,'wage'].astype(float)\n",
    "\n",
    "# wageFreq is \"monthly\" or \"weekly\"\n",
    "df_merged.loc[:,'wageFreq'] = pd.Series(None)\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62', '31', '71', '72']),'wageFreq'] = \"m\"\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['41', '42', '51']),'wageFreq'] = \"w\"\n",
    "\n",
    "## End Getting Wages\n",
    "\n",
    "## Get Hours Worked.\n",
    "time_cols = ['b6q6_3pt1_Act1_per_fv', 'b6q6_3pt1_Act2_per_fv', 'b6q6_3pt2_Act1_per_fv', \\\n",
    "             'b6q6_3pt2_Act2_per_fv', 'b6q6_3pt3_Act1_per_fv', 'b6q6_3pt3_Act2_per_fv', \\\n",
    "             'b6q6_3pt4_Act1_per_fv', 'b6q6_3pt4_Act2_per_fv', 'b6q6_3pt5_Act1_per_fv', \\\n",
    "             'b6q6_3pt5_Act2', 'b6q6_3pt6_Act1', 'b6q6_3pt6_Act2', 'b6q6_3pt7_Act1', \\\n",
    "             'b6q6_3pt7_Act2']\n",
    "for col in time_cols:\n",
    "    df_merged.loc[:,col] = df_merged.loc[:,col].astype(float)\n",
    "df_merged.loc[:,'weeklyhrs'] = df_merged.loc[:,time_cols].sum(axis=1)\n",
    "## End Hours Worked\n",
    "\n",
    "df_merged = df_merged[(df_merged['weeklyhrs'] > 0)]\n",
    "\n",
    "# 144 hrs time endowment. Drop any with more than that.\n",
    "# df_merged = df_merged[df_merged['weeklyhrs'] <= 144]\n",
    "# Can remove lower end?  Those working very very few hrs.\n",
    "# df_merged = df_merged[df_merged['weeklyhrs'] > df_merged['weeklyhrs'].quantile(0.001)]\n",
    "df_merged[\"factor\"] = df_merged[\"weeklyhrs\"]\n",
    "df_merged.loc[df_merged[\"wageFreq\"] == \"m\", \"factor\"] = 4*df_merged.loc[df_merged[\"wageFreq\"] == \"m\",\"weeklyhrs\"]\n",
    "df_merged['hourlywage'] = df_merged['wage']/df_merged['factor']\n",
    "# df_merged['hourlywage'][df_merged['wageFreq'] == \"w\"] = df_merged['wage'][df_merged['wageFreq'] == \"w\"]/df_merged['weeklyhrs'][df_merged['wageFreq'] == \"w\"]\n",
    "# df_merged['hourlywage'][df_merged['wageFreq'] == \"m\"] = df_merged['wage'][df_merged['wageFreq'] == \"m\"]/(4.34*df_merged['weeklyhrs'][df_merged['wageFreq'] == \"m\"])\n",
    "# ## Part Time or Full Time?\n",
    "df_merged.loc[:,'FT'] = pd.Series(None)\n",
    "df_merged.loc[df_merged['weeklyhrs'] >= 40,'FT'] = \"FT\"\n",
    "df_merged.loc[df_merged['weeklyhrs'] < 40 ,'FT'] = \"PT\"\n",
    "# # df_merged['hourlywage'][df_merged['wageFreq'] == \"w\"] = df_merged['hourlywage'][df_merged['wageFreq'] == \"w\"]['wage']\n",
    "# ## End Part Time or Full Time\n",
    "df_merged['hourlywage'] = df_merged['hourlywage'].astype(float)\n",
    "df_merged = df_merged[(df_merged['hourlywage'] < df_merged['hourlywage'].quantile(0.999))]\n",
    "# df_merged['hourlywage'] = sum(df_merged['hourlywage']*df_merged['per_weight_ann'])/sum(df_merged['per_weight_ann'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "193c088b-dbe1-4da2-bdb1-512ed00e1ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b4q5_per_fv\n",
       "1    52.813778\n",
       "2    42.837328\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[[\"b4q5_per_fv\", \"weeklyhrs\", \"weight\"]].groupby([\"b4q5_per_fv\"]).apply(lambda x: np.average(x.weeklyhrs, weights=x.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "f2b61a3a-1ecf-4e51-a9c3-aea6cfcee289",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1899.000000\n",
       "mean       92.854907\n",
       "std        60.956827\n",
       "min         0.000000\n",
       "25%        52.083333\n",
       "50%        76.754386\n",
       "75%       117.953193\n",
       "max       409.836066\n",
       "Name: hourlywage, dtype: float64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do Self Employed Workers have wages? \n",
    "# Check for 21: \n",
    "df_merged.loc[df_merged[\"b5pt1q3_per_fv\"] == \"12\",'hourlywage'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "7eb7b749-90de-4dfc-8513-b7e26cd10f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b4q5_per_fv\n",
       "1    56.718866\n",
       "2    45.385898\n",
       "dtype: float64"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_merged[df_merged[\"hourlywage\"] > 0]\n",
    "# df_merged = df_merged[df_merged[\"b5pt1q3_per_fv\"].isin(REG_EMP_CODES+CASUAL_EMP_CODES)]\n",
    "df_merged[df_merged[\"FT\"] == \"FT\"].groupby(['b4q5_per_fv']).apply(lambda x: np.average(x.hourlywage, weights=x.weight)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e482c23-0bef-4e2c-a6c8-74f95cb8b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['b4q5_per_fv'] == '2'][['hourlywage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "69f2821d-9f10-4f9a-8834-b3649d2a08bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create age categories\n",
    "bins = [15, 25, 30, 36, 42, 50]\n",
    "labels = ['15-25', '26-30', '31-36', '37-42', '43-49']\n",
    "\n",
    "# Create a new column with the age groups\n",
    "df_merged['age_group'] = pd.cut(df_merged['b4q6_per_fv'], bins=bins, labels=labels, right=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "812d0312-4fc0-4611-ac1d-b409a29f7e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: b4q6_per_fv, dtype: int16)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"b4q6_per_fv\"][df_merged[\"age_group\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "5ba87ec5-1540-4740-b84c-1c28dca49f80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 8.0, 7.0, 6.0, 12.0, 10.0, 13.0, 11.0, 5.0, 4.0, 2.0, 3.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Education: Keep only that which is not empty\n",
    "df_merged = df_merged[df_merged[\"b4q8_per_fv\"] != \"\"]\n",
    "# Convert string to float for easy transformations: \n",
    "df_merged.loc[:,\"b4q8_per_fv\"] = df_merged.loc[:,\"b4q8_per_fv\"].astype(float)\n",
    "df_merged[\"b4q8_per_fv\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "dc254a63-f596-47e6-abe9-862987f47513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign labels to years of eduction\n",
    "df_merged.loc[:,\"educ\"] = pd.Series(None)\n",
    "df_merged.loc[df_merged[\"b4q8_per_fv\"] <= 4, \"educ\"] = \"UN_EDU\"\n",
    "df_merged.loc[(df_merged[\"b4q8_per_fv\"] <= 8) & (df_merged[\"b4q8_per_fv\"] > 4), \"educ\"] = \"LE_HS\"\n",
    "df_merged.loc[df_merged[\"b4q8_per_fv\"] == 10, \"educ\"] = \"HS\"\n",
    "df_merged.loc[df_merged[\"b4q8_per_fv\"] == 11, \"educ\"] = \"SM_COL\"\n",
    "df_merged.loc[df_merged[\"b4q8_per_fv\"] > 11, \"educ\"] = \"COL_AM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "381898e1-d522-40c0-a4d6-e7200f511816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged.loc[:,\"sector\"] = pd.Series(None)\n",
    "df_merged.loc[(df_merged[\"b5pt1q3_per_fv\"].isin(NOT_REG_CODES)), \"sector\"] = \"informal\"\n",
    "df_merged.loc[(df_merged[\"b5pt1q3_per_fv\"].isin(REG_EMP_CODES)), \"sector\"] = \"formal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ee1438b4-78c1-4eec-93cf-27bdae7011bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged[\"sector\"].isna()][\"b5pt1q3_per_fv\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "833d44df-5f0e-471e-88b1-8d412208b3e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_export = df_merged[['b4q5_per_fv', \"hourlywage\", \"age_group\", \"educ\", \"state_per_fv\", \"b1q3_per_fv\", \"sector\", \"FT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "018af4af-79e2-4c68-8989-c16016a27c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting dummies for all categorical variables \n",
    "df_export.to_stata(\"../../data/proc/wage_reg.dta\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
