{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12bf6fa8-6998-44b5-a74d-909bb93aca38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3d7d98d3-72a6-4faf-b5ad-28114c7157b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################# GLOBAL VARIABLES ######################\n",
    "\n",
    "# Definitions from PLFS 2018-19 Annual Report, Concepts and Definitions (2.38.1)\n",
    "# Problematic codes for self employed criteria: `21` - worked in household enterprises (self-employed) as helper\n",
    "SELF_EMP_CODES = [\"11\", \"12\", \"21\", \"61\", \"62\",]\n",
    "REG_EMP_CODES = [\"31\", \"71\", \"72\"]\n",
    "CASUAL_EMP_CODES = [\"41\", \"42\", \"51\"]\n",
    "\n",
    "NOT_REG_CODES = SELF_EMP_CODES + CASUAL_EMP_CODES\n",
    "\n",
    "EMP_CODES = SELF_EMP_CODES + REG_EMP_CODES + CASUAL_EMP_CODES\n",
    "UNEMP_CODES = [\"81\", \"82\"]\n",
    "LF_CODES = EMP_CODES + UNEMP_CODES\n",
    "NOT_IN_LF_CODES = [str(x) for x in list(range(91,100))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c0f04551-ce55-4ec9-8b5d-e2af5cef9ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Main Data File\n",
    "df_per_fv = pd.read_stata(\"../../data/raw/plfs/plfs_2018_19/PerV1_2018-19.dta\")\n",
    "df_per_rv = pd.read_stata(\"../../data/raw/plfs/plfs_2018_19/PerRV_2018-19.dta\") \n",
    "df_hh_fv = pd.read_stata('../../data/raw/plfs/plfs_2018_19/HHV1_2018-19.dta')\n",
    "df_hh_rv = pd.read_stata('../../data/raw/plfs/plfs_2018_19/HHRV_2018-19.dta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "866f3faa-ff6e-4711-9989-c025ef582cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533264, 104)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_per_rv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e12c62-37e9-40b6-83f3-a4d8a9ecb4d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### On whether to use Repeat Visit along with the First Visit Data (even if to use it as a pooled cross-section) \n",
    "\n",
    "There are two ways in which employment status is determined: 1) What you did in the last 365 days. 2) What you did in the last week. Repeat visit does not have information about the first one. Only the Weekly status. Using either has its pros and cons. While the first may be more accurate picture of participation while the second has more data. I am sticking with First Visit only (for simplicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df854e8c-07dc-415a-b3ef-7e10ee81190b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This block makes a csv file which stores the variable name-label pairs. \n",
    "df_per_fv_layout = pd.read_excel(\"../../data/raw/plfs/plfs_2018_19/Data_LayoutPLFS.xlsx\", header=38, usecols=[1], nrows=129)\n",
    "df_hh_fv_layout = pd.read_excel(\"../../data/raw/plfs/plfs_2018_19/Data_LayoutPLFS.xlsx\", header=2, usecols=[1], nrows=32)\n",
    "# df_hh_rv_layout = copy.deepcopy(df_hh_fv_layout) \n",
    "# df_per_rv_layout = pd.read_excel(\"../../data/raw/plfs/plfs_2018_19/Data_LayoutPLFS.xlsx\", header=171, usecols=[1], nrows=104)\n",
    "\n",
    "pd.DataFrame({'varName': df_per_fv.columns, 'varLabel': df_per_fv_layout[\"Full Name\"]}).to_csv(\"../../data/proc/ColNameLabelPerV1_2018_19.csv\", index=False)\n",
    "pd.DataFrame({'varName': df_hh_fv.columns, 'varLabel': df_hh_fv_layout[\"Full Name\"]}).to_csv(\"../../data/proc/ColNameLabelHHV1_2018_19.csv\", index=False)\n",
    "# pd.DataFrame({'varName': df_hh_rv.columns, 'varLabel': df_hh_rv_layout[\"Full Name\"]}).to_csv(\"../../data/proc/ColNameLabelHHRV_2018_19.csv\", index=False)\n",
    "# pd.DataFrame({'varName': df_per_rv.columns, 'varLabel': df_per_rv_layout[\"Full Name\"]}).to_csv(\"../../data/proc/ColNameLabelPerRV_2018_19.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6c6e4cd-a6da-4a9f-8e12-92a8ef151032",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_17600\\3645976382.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_per_fv.loc[:,'HHID'] = df_per_fv.quarter_per_fv + df_per_fv.visit_per_fv + df_per_fv.fsu_per_fv \\\n"
     ]
    }
   ],
   "source": [
    "# Merge HH and Per dataset\n",
    "# generate merge keys for both hh and per datasets and merge\n",
    "df_per_fv.loc[:,'HHID'] = df_per_fv.quarter_per_fv + df_per_fv.visit_per_fv + df_per_fv.fsu_per_fv \\\n",
    "                    + df_per_fv.b1q13_per_fv + df_per_fv.b1q14_per_fv + df_per_fv.b1q15_per_fv\n",
    "\n",
    "df_hh_fv.loc[:,'HHID'] = df_hh_fv.qtr_hh_rv + df_hh_fv.visit_hh_rv + df_hh_fv.b1q1_hh_rv \\\n",
    "                    + df_hh_fv.b1q13_hh_rv + df_hh_fv.b1q14_hh_rv + df_hh_fv.b1q15_hh_rv \n",
    "\n",
    "\n",
    "df_temp = pd.merge(left=df_per_fv, right=df_hh_fv, on='HHID', how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5b8d3f61-8894-41ca-886b-6093aaaf3f21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just so that I don't have to merge again and again\n",
    "df_merged = copy.deepcopy(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "94c80b89-a3f3-42e6-815e-4d20749e9898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420757, 162)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6328f5-e82c-45b7-a015-9a4ba84ad62a",
   "metadata": {},
   "source": [
    "# Create variables first -- then subset!! Otherwise I'll run into problems with selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "479727c7-393d-45e9-8bdf-6ed864420961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######### Employment Status \n",
    "## This is calculated using UPSS (Usual Principal or Subsidiary Status) definition. See Afridi et al. (2022) Appendix B\n",
    "\n",
    "df_merged.loc[:,\"lfp_ps\"] = df_merged.b5pt1q3_per_fv.apply(lambda x: 1 if x in LF_CODES else 0)\n",
    "df_merged[\"lfp_ss\"] = df_merged.b5pt2q3_per_fv.apply(lambda x: 1 if x in LF_CODES else 0)\n",
    "df_merged[\"lfp_ps_ss\"] = df_merged['lfp_ps'] + df_merged['lfp_ss']\n",
    "\n",
    "df_merged.loc[:,\"emp_ps\"] = df_merged.b5pt1q3_per_fv.apply(lambda x: 1 if x in EMP_CODES else 0)\n",
    "df_merged[\"emp_ss\"] = df_merged.b5pt2q3_per_fv.apply(lambda x: 1 if x in EMP_CODES else 0)\n",
    "df_merged[\"emp_ps_ss\"] = df_merged['emp_ps'] + df_merged['emp_ss']\n",
    "/\n",
    "df_merged.loc[:,'EMP'] = 0\n",
    "df_merged.loc[df_merged['emp_ps_ss'] > 0, 'EMP'] = 1\n",
    "\n",
    "df_merged.loc[:,\"LFP\"] = 0\n",
    "df_merged.loc[df_merged[\"lfp_ps_ss\"] > 0,\"LFP\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf065810-b56a-4566-9728-402590d724c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### Make wage variable.\n",
    "# These will exist only for those that are employed so I will subset.\n",
    "# DONT SUBSET ANY MORE THAN YOU HAVE TO!!!!!!\n",
    "# df_merged = df_merged[df_merged['EMP'] == 1]\n",
    "df_merged.loc[:, \"wage\"] = 0\n",
    "# Wage column names\n",
    "wage_cols = ['b6q9_per_fv', 'b6q10_per_fv', \\\n",
    "             'b6q9_3pt1_Act1_per_fv', 'b6q9_3pt1_Act2_per_fv', 'b6q9_3pt2_Act1_per_fv', \\\n",
    "             'b6q9_3pt2_Act2_per_fv', 'b6q9_3pt3_Act1_per_fv', 'b6q9_3pt3_Act2_per_fv', \\\n",
    "             'b6q9_3pt4_Act1_per_fv', 'b6q9_3pt4_Act2_per_fv', 'b6q9_3pt5_Act1_per_fv', \\\n",
    "             'b6q9_3pt5_Act2', 'b6q9_Act2_3pt6', 'b6q9_3pt6_Act1', 'b6q9_Act1_3pt7', \\\n",
    "             'b6q9_Act2_3pt7']\n",
    "# these objects are strings so need to be converted to float.\n",
    "for col in wage_cols:\n",
    "    df_merged.loc[:,col] = df_merged.loc[:,col].astype(float)\n",
    "\n",
    "\n",
    "# Some codes have salaries given for last 30 days.\n",
    "# so extracting them here:\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['31', '71', '72']),'wage'] = df_merged.loc[df_merged['b6q5_per_fv'].isin(['31', '71', '72']),'b6q9_per_fv']\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62']),'wage'] = df_merged.loc[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62']),'b6q10_per_fv']\n",
    "\n",
    "# Next, get wages for other codes (from their weekly activities)\n",
    "# that have wages by day.\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['41', '42', '51']),'wage'] = \\\n",
    "                                        df_merged[df_merged['b6q5_per_fv'].isin(['41', '42', '51'])]\\\n",
    "                                               [['b6q9_3pt1_Act1_per_fv', 'b6q9_3pt1_Act2_per_fv', 'b6q9_3pt2_Act1_per_fv', \\\n",
    "                                                 'b6q9_3pt2_Act2_per_fv', 'b6q9_3pt3_Act1_per_fv', 'b6q9_3pt3_Act2_per_fv', \\\n",
    "                                                 'b6q9_3pt4_Act1_per_fv', 'b6q9_3pt4_Act2_per_fv', 'b6q9_3pt5_Act1_per_fv', \\\n",
    "                                                 'b6q9_3pt5_Act2', 'b6q9_Act2_3pt6', 'b6q9_3pt6_Act1', 'b6q9_Act1_3pt7', \\\n",
    "                                                 'b6q9_Act2_3pt7']].sum(axis=1)\n",
    "\n",
    "\n",
    "# Changing `wage` type from object to float.\n",
    "df_merged.loc[:,'wage'] = df_merged.loc[:,'wage'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8117ce39-dc3e-4b30-9dc6-03a9c7e84e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# wageFreq is \"monthly\" or \"weekly\": Will need this for computing daily wage or hourly wage\n",
    "df_merged.loc[:,'wageFreq'] = pd.Series(None)\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62', '31', '71', '72']),'wageFreq'] = \"m\"\n",
    "df_merged.loc[df_merged['b6q5_per_fv'].isin(['41', '42', '51']),'wageFreq'] = \"w\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2195d841-0a37-457c-883e-124e0ab5908a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Getting Hourly wage\n",
    "\n",
    "df_merged.loc[:,\"weeklyhrs\"] = 0\n",
    "## Get Hours Worked.\n",
    "time_cols = ['b6q6_3pt1_Act1_per_fv', 'b6q6_3pt1_Act2_per_fv', 'b6q6_3pt2_Act1_per_fv', \\\n",
    "             'b6q6_3pt2_Act2_per_fv', 'b6q6_3pt3_Act1_per_fv', 'b6q6_3pt3_Act2_per_fv', \\\n",
    "             'b6q6_3pt4_Act1_per_fv', 'b6q6_3pt4_Act2_per_fv', 'b6q6_3pt5_Act1_per_fv', \\\n",
    "             'b6q6_3pt5_Act2', 'b6q6_3pt6_Act1', 'b6q6_3pt6_Act2', 'b6q6_3pt7_Act1', \\\n",
    "             'b6q6_3pt7_Act2']\n",
    "for col in time_cols:\n",
    "    df_merged.loc[:,col] = df_merged.loc[:,col].astype(float)\n",
    "df_merged.loc[df_merged[\"EMP\"] == 1,'weeklyhrs'] = df_merged.loc[df_merged[\"EMP\"] == 1,time_cols].sum(axis=1)\n",
    "## End Hours Worked\n",
    "# What will be the denominator?\n",
    "df_merged[\"total_hrs\"] = df_merged[\"weeklyhrs\"]\n",
    "df_merged.loc[df_merged[\"wageFreq\"] == \"m\", \"total_hrs\"] = 4*df_merged.loc[df_merged[\"wageFreq\"] == \"m\",\"weeklyhrs\"]\n",
    "# Get hourly wage\n",
    "df_merged.loc[:,'hourlywage'] = pd.Series(None)\n",
    "df_merged.loc[df_merged['weeklyhrs'] > 0, 'hourlywage'] = df_merged.loc[df_merged['weeklyhrs'] > 0,'wage']/df_merged.loc[df_merged['weeklyhrs'] > 0,'total_hrs']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76b7b91e-fa3e-4e41-9fae-9e90a8255924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full Time Status might be useful.\n",
    "df_merged.loc[:,'FT'] = pd.Series(None)\n",
    "df_merged.loc[df_merged['weeklyhrs'] >= 40,'FT'] = \"FT\"\n",
    "df_merged.loc[df_merged['weeklyhrs'] < 40 ,'FT'] = \"PT\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c367f36-8f7e-469f-83fc-f170ae9c0453",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    113250.000000\n",
       "mean         56.103604\n",
       "std         102.160203\n",
       "min         -89.285714\n",
       "25%          26.785714\n",
       "50%          40.178571\n",
       "75%          66.964286\n",
       "max       26785.714286\n",
       "Name: hourlywage, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['FT'] == \"FT\"][\"hourlywage\"].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d564fc7c-4a74-4cb4-8e3c-f768b623ee1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Daily Wage\n",
    "df_merged.loc[:,'dailywage'] = pd.Series(None)\n",
    "df_merged.loc[df_merged[\"wageFreq\"] == \"m\",\"dailywage\"] = df_merged.loc[df_merged[\"wageFreq\"] == \"m\",\"wage\"]/30\n",
    "df_merged.loc[df_merged[\"wageFreq\"] == \"w\",\"dailywage\"] = df_merged.loc[df_merged[\"wageFreq\"] == \"w\",\"wage\"]/7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "183ad4fc-0cff-4648-a868-f320f86e8d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43197.000000\n",
       "mean       566.686866\n",
       "std        552.535926\n",
       "min          0.000000\n",
       "25%        250.000000\n",
       "50%        400.000000\n",
       "75%        733.333333\n",
       "max      40000.000000\n",
       "Name: dailywage, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['b6q5_per_fv'].isin(['31', '71', '72'])][\"dailywage\"].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbe61bb6-6892-41b8-9642-8257731a56a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     97273.000000\n",
       "mean        280.085356\n",
       "std         735.975878\n",
       "min        -666.666667\n",
       "25%         100.000000\n",
       "50%         233.333333\n",
       "75%         357.142857\n",
       "max      200000.000000\n",
       "Name: dailywage, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['b6q5_per_fv'].isin(['11', '12', '21', '61', '62','41', '42', '51'])][\"dailywage\"].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26a776dc-42b4-4560-a433-83d2fced8b18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subsetting: \n",
    "# 1. (Currently) married people. \n",
    "df_merged = df_merged[df_merged[\"b4q7_per_fv\"] == \"2\"]\n",
    "# 2. Urban.\n",
    "df_merged = df_merged[df_merged[\"b1q3_per_fv\"] == \"2\"]\n",
    "# 3. Drop 3rd gender\n",
    "df_merged = df_merged[df_merged[\"b4q5_per_fv\"] != \"3\"]\n",
    "# 4. Then make a dataframe with husbands and wives matched. Then subset women with age 15-49. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "447485ee-45f8-403f-97e7-fa6499d62125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, I create a dataframe with husbands and wives. \n",
    "# First, remove all entries that do not have relation to head of HH as: 1,2,3 or 4. These relations are the only ones where I can identify a marriage. \n",
    "df_merged = df_merged[df_merged[\"b4q4_per_fv\"].isin([\"1\",\"2\",\"3\",\"4\"])]\n",
    "\n",
    "# Next, need to label each person in a HH as husband/wife. \n",
    "df_merged.loc[:,\"spouse\"] = \"husband\"\n",
    "df_merged.loc[df_merged[\"b4q5_per_fv\"] == \"2\",\"spouse\"] = \"wife\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14a2fec8-a098-48c0-bd2a-afc3636aecdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b4q4_per_fv  spouse \n",
       "1            husband    34593\n",
       "2            wife       33692\n",
       "4            wife        8192\n",
       "3            husband     7859\n",
       "1            wife        1140\n",
       "3            wife         838\n",
       "4            husband      314\n",
       "2            husband      174\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[[\"b4q4_per_fv\", \"spouse\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09374b8d-0bce-43ac-8397-0f98fcb555db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_17600\\1478790817.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_husb.loc[:,\"rel_key\"] = None\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_17600\\1478790817.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wife.loc[:,\"rel_key\"] = None\n"
     ]
    }
   ],
   "source": [
    "# Make two separate dataframes for husbands and wives, merge each husband with his wife.\n",
    "# \n",
    "# In each HH, there is a possibility that you have two husbands and two wives. \n",
    "# Separate the husbands and wives. \n",
    "df_husb = df_merged[df_merged[\"spouse\"] == \"husband\"]\n",
    "df_wife = df_merged[df_merged[\"spouse\"] == \"wife\"]\n",
    "\n",
    "# # Now, define a mapping -- 1<->2, 3<->4 within each hh has to be mapped.\n",
    "# # The relationship key will be kept the same as b4q4_per_fv for husbands. Relationship key \n",
    "# # for wives will be according to the merge map. \n",
    "df_husb.loc[:,\"rel_key\"] = None\n",
    "df_wife.loc[:,\"rel_key\"] = None\n",
    "df_husb.loc[:,\"rel_key\"] = df_husb.loc[:,\"b4q4_per_fv\"]\n",
    "merge_map = {\"1\":\"2\", \"2\":\"1\", \"3\":\"4\", \"4\":\"3\"}\n",
    "df_wife.loc[:,\"rel_key\"] = df_wife.loc[:,\"b4q4_per_fv\"].apply(lambda x: merge_map[x])\n",
    "# # df_husb[\"rel_key\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bce4b31-fd94-47bd-a225-e52d2cd0c89d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42940, 179)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_husb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "493f2fd9-f1d4-461e-bbff-1b39edfa4612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43862, 179)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wife.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28bc7780-33cc-442e-946b-97196d3b3035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update column names so that husb. cols have _husb, wives, _wife\n",
    "df_husb.columns = [col+\"_h\" for col in df_husb.columns]\n",
    "df_wife.columns = [col+\"_w\" for col in df_wife.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "237d1a08-24af-4c7d-a661-ecfef60a1ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_husb_wife = pd.merge(left=df_husb, right=df_wife, left_on=[\"HHID_h\", \"rel_key_h\"], right_on=[\"HHID_w\", \"rel_key_w\"], how=\"outer\", indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bc7df92-f157-4b90-b2d7-077dcab4f673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          43825\n",
       "right_only     2329\n",
       "left_only      1524\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_husb_wife[\"_merge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94835218-bda3-4f22-b397-ecc2701c4109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_husb_wife = df_husb_wife[df_husb_wife[\"_merge\"] == \"both\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "506908d9-bde3-4d05-b14f-8ba247bc4e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, df_husb_wife is my base dataframe. First I will subset using wife's age: \n",
    "df_husb_wife = df_husb_wife[(df_husb_wife[\"b4q6_per_fv_w\"] >= 15) & (df_husb_wife[\"b4q6_per_fv_w\"] <= 49)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba286bfa-ddd2-4dc6-9b27-2a7d6b1aefa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_husb_wife = df_husb_wife[df_husb_wife[\"b4q8_per_fv_h\"] != \"\"]\n",
    "df_husb_wife = df_husb_wife[df_husb_wife[\"b4q8_per_fv_w\"] != \"\"]\n",
    "\n",
    "df_husb_wife.loc[:,\"hs_h\"] = 0\n",
    "# For those who don't have a \"\" in their education field, check if edu >= 11\n",
    "df_husb_wife.loc[df_husb_wife[\"b4q8_per_fv_h\"].astype(float) >= 10 ,\"hs_h\"] = 1\n",
    "\n",
    "df_husb_wife.loc[:,\"hs_w\"] = 0\n",
    "# For those who don't have a \"\" in their education field, check if edu >= 11\n",
    "df_husb_wife.loc[df_husb_wife[\"b4q8_per_fv_w\"].astype(float) >= 10 ,\"hs_w\"] = 1\n",
    "\n",
    "\n",
    "df_husb_wife.loc[:,\"dip_h\"] = 0\n",
    "# For those who don't have a \"\" in their education field, check if edu >= 11\n",
    "df_husb_wife.loc[df_husb_wife[\"b4q8_per_fv_h\"].astype(float) >= 11 ,\"dip_h\"] = 1\n",
    "\n",
    "df_husb_wife.loc[:,\"dip_w\"] = 0\n",
    "df_husb_wife.loc[df_husb_wife[\"b4q8_per_fv_w\"].astype(float) >= 11 ,\"dip_w\"] = 1\n",
    "\n",
    "df_husb_wife.loc[:,\"col_h\"] = 0\n",
    "df_husb_wife.loc[df_husb_wife[\"b4q8_per_fv_h\"].astype(float) >= 12,\"col_h\"] = 1\n",
    "\n",
    "df_husb_wife.loc[:,\"col_w\"] = 0\n",
    "df_husb_wife.loc[df_husb_wife[\"b4q8_per_fv_w\"].astype(float) >= 12,\"col_w\"] = 1\n",
    "\n",
    "df_husb_wife.loc[:,\"grad_h\"] = 0\n",
    "df_husb_wife.loc[df_husb_wife[\"b4q8_per_fv_h\"].astype(float) >= 13,\"grad_h\"] = 1\n",
    "\n",
    "df_husb_wife.loc[:,\"grad_w\"] = 0\n",
    "df_husb_wife.loc[df_husb_wife[\"b4q8_per_fv_w\"].astype(float) >= 13,\"grad_w\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09279418-a77c-400d-9ebc-ba1dd67a6ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_husb_wife.to_pickle(\"df_husb_wife.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
